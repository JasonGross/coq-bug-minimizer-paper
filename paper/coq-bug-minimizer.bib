@PhdThesis{zimmermann:tel-02451322,
  author = {Zimmermann, Théo},
  school = {{Universit{\'e} de Paris}},
  title  = {{Challenges in the collaborative evolution of a proof language and its ecosystem}},
  year   = {2019},
  url    = {https://hal.inria.fr/tel-02451322},
}

@Misc{coqpl-15-coq-bug-minimizer,
  author           = {Jason Gross},
  month            = jan,
  note             = {Presented at \href{https://coqpl.cs.washington.edu/2014/07/31/}{The First International Workshop on Coq for PL (CoqPL'15)}},
  title            = {Coq Bug Minimizer},
  year             = {2015},
  abstract         = {Are bugs the bane of your existence? Do you dread Coq upgrades, because they mean you'll have to spend days tracking down subtle failures deep in your developments? Have you ever hit an anomaly that just wouldn't go away, and wished you understood what triggered it? Have you ever been tormented by two blocks of code that looked identical, but behaved differently? Do you wish you submit more helpful error reports, but don't want to put in the time to construct minimal examples? If you answered ``yes'' to any of these questions, then the Coq Bug Minimizer is for you! Clone your own copy at \url{https://github.com/JasonGross/coq-bug-finder}.},
  modificationdate = {2014-10-07T00:00:00},
  owner            = {Jason},
  reviews          = {https://jasongross.github.io/papers/2015-coq-bug-minimizer-reviews.txt},
  url              = {https://jasongross.github.io/papers/2015-coq-bug-minimizer.pdf},
}

@InProceedings{Cleve2000,
  author        = {Holger Cleve and Andreas Zeller},
  booktitle     = {Proceedings of the Fourth International Workshop on Automated Debugging, {AADEBUG} 2000, Munich, Germany, August 28-30th, 2000},
  title         = {Finding Failure Causes through Automated Testing},
  year          = {2000},
  editor        = {Mireille Ducassé},
  archiveprefix = {arxiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/aadebug/CleveZ00.bib},
  eprint        = {cs/0012009},
  primaryclass  = {cs},
  timestamp     = {Thu, 09 Jan 2020 16:10:06 +0100},
}

@Book{zeller2009programs,
  author    = {Andreas Zeller},
  publisher = {Elsevier},
  title     = {Why Programs Fail: A Guide to Systematic Debugging},
  year      = {2009},
}

@InProceedings{Burger2005,
  author    = {Burger, Martin and Lehmann, Karsten and Zeller, Andreas},
  booktitle = {Companion to the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  title     = {Automated Debugging in Eclipse},
  year      = {2005},
  address   = {New York, NY, USA},
  pages     = {184--185},
  publisher = {Association for Computing Machinery},
  series    = {OOPSLA '05},
  abstract  = {Your program fails. What is the cause of this failure? In this demo, we present two delta debugging plug-ins for the Eclipse environment which isolate failure causes in the program history and in the program's execution.},
  doi       = {10.1145/1094855.1094926},
  isbn      = {1595931937},
  keywords  = {testing, programming environments, program comprehension, debugging, version control},
  location  = {San Diego, CA, USA},
  numpages  = {2},
}

@Misc{delta,
  author   = {Daniel S. Wilkerson and Scott McPeak},
  month    = feb,
  note     = {Presented at \href{https://web.archive.org/web/20071224085116/http://www.codecon.org/2006/program.html}{CodeCon 2006}},
  title    = {{d}elta - Delta assists you in minimizing ``interesting'' files subject to a test of their interestingness},
  year     = {2006},
  abstract = {History: Scott and I were working on various static-analysis projects (our research group: http://osq.cs.berkeley.edu/). We had large inputs that would cause our tools to fail and minimizing by hand was hopeless, so I we wrote delta. With delta, no matter how big you start with, you always end up with about a page or two of code, even a quarter-million line input we tried once. Microsoft Research heard about it through the grapevine and asked someone to come to my office and ask me if I would release it as open source, so I did. Maybe they didn't want to write an email to me endorsing an open source project on record? I don't know. Now this thing is everywhere: it is taught in the Stanford and Berkeley software engineering classes and the gcc people use it. See the website.

Our implementation is based on the Delta Debugging algorithm: http://www.st.cs.uni-sb.de/dd/

Demo: I will probably minimize a file while wearing no clothes. Just kidding; I wouldn't actually minimize a file in public.

Future Plans: The gcc people seem to like it and one of them has checkin privileges so I suppose it will keep getting better. I have an idea to generalize the algorithm. Most people have ideas on how to make it work better for *their* use of it, but these schemes tend to make it worse in general.},
  url      = {https://github.com/dsw/delta},
}

@InProceedings{Zeller2002,
  author    = {Zeller, Andreas},
  booktitle = {Proceedings of the 10th ACM SIGSOFT Symposium on Foundations of Software Engineering},
  title     = {Isolating Cause-Effect Chains from Computer Programs},
  year      = {2002},
  address   = {New York, NY, USA},
  pages     = {1--10},
  publisher = {Association for Computing Machinery},
  series    = {SIGSOFT '02/FSE-10},
  abstract  = {Consider the execution of a failing program as a sequence of program states. Each state induces the following state, up to the failure. Which variables and values of a program state are relevant for the failure? We show how the Delta Debugging algorithm isolates the relevant variables and values by systematically narrowing the state difference between a passing run and a failing run—by assessing the outcome of altered executions to determine wether a change in the program state makes a difference in the test outcome. Applying Delta Debugging to multiple states of the program automatically reveals the cause-effect chain of the failure—that is, the variables and values that caused the failure.In a case study, our prototype implementation successfully isolated the cause-effect chain for a failure of the GNU C compiler: "Initially, the C program to be compiled contained an addition of 1.0; this caused an addition operator in the intermediate RTL representation; this caused a cycle in the RTL tree—and this caused the compiler to crash."},
  doi       = {10.1145/587051.587053},
  isbn      = {1581135149},
  keywords  = {tracing, testing, program comprehension, automated debugging},
  location  = {Charleston, South Carolina, USA},
  numpages  = {10},
}

@Article{coq-coq-correct,
  author     = {Sozeau, Matthieu and Boulier, Simon and Forster, Yannick and Tabareau, Nicolas and Winterhalter, Théo},
  journal    = {Proc. ACM Program. Lang.},
  title      = {Coq Coq Correct! Verification of Type Checking and Erasure for Coq, in Coq},
  year       = {2019},
  month      = dec,
  number     = {POPL},
  volume     = {4},
  abstract   = {Coq is built around a well-delimited kernel that perfoms typechecking for definitions in a variant of the Calculus of Inductive Constructions (CIC). Although the metatheory of CIC is very stable and reliable, the correctness of its implementation in Coq is less clear. Indeed, implementing an efficient type checker for CIC is a rather complex task, and many parts of the code rely on implicit invariants which can easily be broken by further evolution of the code. Therefore, on average, one critical bug has been found every year in Coq. This paper presents the first implementation of a type checker for the kernel of Coq (without the module system and template polymorphism), which is proven correct in Coq with respect to its formal specification and axiomatisation of part of its metatheory. Note that because of Gödel's incompleteness theorem, there is no hope to prove completely the correctness of the specification of Coq inside Coq (in particular strong normalisation or canonicity), but it is possible to prove the correctness of the implementation assuming the correctness of the specification, thus moving from a trusted code base (TCB) to a trusted theory base (TTB) paradigm. Our work is based on the MetaCoq project which provides metaprogramming facilities to work with terms and declarations at the level of this kernel. Our type checker is based on the specification of the typing relation of the Polymorphic, Cumulative Calculus of Inductive Constructions (PCUIC) at the basis of Coq and the verification of a relatively efficient and sound type-checker for it. In addition to the kernel implementation, an essential feature of Coq is the so-called extraction: the production of executable code in functional languages from Coq definitions. We present a verified version of this subtle type-and-proof erasure step, therefore enabling the verified extraction of a safe type-checker for Coq.},
  address    = {New York, NY, USA},
  articleno  = {8},
  doi        = {10.1145/3371076},
  issue_date = {January 2020},
  keywords   = {type checker, certification, proof assistants},
  numpages   = {28},
  publisher  = {Association for Computing Machinery},
}


@inproceedings{ochoa2022breakbot,
   author    = {Lina Ochoa and Thomas Degueule and Jean-Rémy Falleri},
   title     = {{BreakBot}: Analyzing the Impact of Breaking Changes to
Assist Library Evolution},
   booktitle = {44th {IEEE/ACM} International Conference on Software
Engineering: New Ideas and Emerging Results, {ICSE} {(NIER)} 2022},
   publisher = {{IEEE}},
   year      = {2022}
}

@Unpublished{zimmermann:hal-03479327,
  author      = {Zimmermann, Théo and Coolen, Julien and Gross, Jason and Pédrot, Pierre-Marie and Gilbert, Gaëtan},
  note        = {working paper or preprint},
  title       = {Extending the team with a project-specific bot},
  month       = dec,
  year        = {2021},
  hal_id      = {hal-03479327},
  hal_version = {v1},
  pdf         = {https://hal.inria.fr/hal-03479327/file/paper.pdf},
  url         = {https://hal.inria.fr/hal-03479327},
}

@InProceedings{quickchick,
  author      = {Paraskevopoulou, Zoe and Hriţcu, Cătălin and Dénès, Maxime and Lampropoulos, Leonidas and Pierce, Benjamin C.},
  booktitle   = {{ITP} 2015 - 6th conference on Interactive Theorem Proving},
  title       = {Foundational Property-Based Testing},
  year        = {2015},
  address     = {Nanjing, China},
  month       = aug,
  publisher   = {Springer},
  series      = {Lecture Notes in Computer Science},
  volume      = {9236},
  doi         = {10.1007/978-3-319-22102-1\_22},
  hal_id      = {hal-01162898},
  hal_version = {v1},
  pdf         = {https://hal.inria.fr/hal-01162898/file/main.pdf},
  url         = {https://hal.inria.fr/hal-01162898},
}

@article{chen_survey_compiler_testing,
author = {Chen, Junjie and Patra, Jibesh and Pradel, Michael and Xiong, Yingfei and Zhang, Hongyu and Hao, Dan and Zhang, Lu},
title = {A Survey of Compiler Testing},
year = {2020},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3363562},
doi = {10.1145/3363562},
abstract = {Virtually any software running on a computer has been processed by a compiler or a compiler-like tool. Because compilers are such a crucial piece of infrastructure for building software, their correctness is of paramount importance. To validate and increase the correctness of compilers, significant research efforts have been devoted to testing compilers. This survey article provides a comprehensive summary of the current state-of-the-art of research on compiler testing. The survey covers different aspects of the compiler testing problem, including how to construct test programs, what test oracles to use for determining whether a compiler behaves correctly, how to execute compiler tests efficiently, and how to help compiler developers take action on bugs discovered by compiler testing. Moreover, we survey work that empirically studies the strengths and weaknesses of current compiler testing research and practice. Based on the discussion of existing work, we outline several open challenges that remain to be addressed in future work.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {4},
numpages = {36},
keywords = {test optimization, test program generation, Compiler testing, compiler debugging, test oracle}
}

@inproceedings{herfert2017automatically,
  title={Automatically reducing tree-structured test inputs},
  author={Herfert, Satia and Patra, Jibesh and Pradel, Michael},
  booktitle={2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  pages={861--871},
  year={2017},
  organization={IEEE}
}

@inproceedings{regehr2012test,
  title={Test-case reduction for C compiler bugs},
  author={Regehr, John and Chen, Yang and Cuoq, Pascal and Eide, Eric and Ellison, Chucky and Yang, Xuejun},
  booktitle={Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation},
  pages={335--346},
  year={2012}
}

@inproceedings{chen2013taming,
  title={Taming compiler fuzzers},
  author={Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
  booktitle={Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation},
  pages={197--208},
  year={2013}
}

@inproceedings{holmes2016mitigating,
  title={Mitigating (and exploiting) test reduction slippage},
  author={Holmes, Josie and Groce, Alex and Alipour, Mohammad Amin},
  booktitle={Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
  pages={66--69},
  year={2016}
}

@inproceedings{emi,
author = {Le, Vu and Afshari, Mehrdad and Su, Zhendong},
title = {Compiler Validation via Equivalence modulo Inputs},
year = {2014},
isbn = {9781450327848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2594291.2594334},
doi = {10.1145/2594291.2594334},
abstract = {We introduce equivalence modulo inputs (EMI), a simple, widely applicable methodology for validating optimizing compilers. Our key insight is to exploit the close interplay between (1) dynamically executing a program on some test inputs and (2) statically compiling the program to work on all possible inputs. Indeed, the test inputs induce a natural collection of the original program's EMI variants, which can help differentially test any compiler and specifically target the difficult-to-find miscompilations.To create a practical implementation of EMI for validating C compilers, we profile a program's test executions and stochastically prune its unexecuted code. Our extensive testing in eleven months has led to 147 confirmed, unique bug reports for GCC and LLVM alone. The majority of those bugs are miscompilations, and more than 100 have already been fixed.Beyond testing compilers, EMI can be adapted to validate program transformation and analysis systems in general. This work opens up this exciting, new direction.},
booktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {216–226},
numpages = {11},
keywords = {equivalent program variants, automated testing, miscompilation, compiler testing},
location = {Edinburgh, United Kingdom},
series = {PLDI '14}
}

@InProceedings{Nitpick,
author="Blanchette, Jasmin Christian
and Nipkow, Tobias",
editor="Kaufmann, Matt
and Paulson, Lawrence C.",
title="Nitpick: A Counterexample Generator for Higher-Order Logic Based on a Relational Model Finder",
booktitle="Interactive Theorem Proving",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="131--146",
abstract="Nitpick is a counterexample generator for Isabelle/HOL that builds on Kodkod, a SAT-based first-order relational model finder. Nitpick supports unbounded quantification, (co)inductive predicates and datatypes, and (co)recursive functions. Fundamentally a finite model finder, it approximates infinite types by finite subsets. As case studies, we consider a security type system and a hotel key card system. Our experimental results on Isabelle theories and the TPTP library indicate that Nitpick generates more counterexamples than other model finders for higher-order logic, without restrictions on the form of the formulas to falsify.",
isbn="978-3-642-14052-5"
}

@inproceedings{yang2011finding,
  title={Finding and understanding bugs in C compilers},
  author={Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
  booktitle={Proceedings of the 32nd ACM SIGPLAN conference on Programming language design and implementation},
  pages={283--294},
  year={2011}
}

@Comment{jabref-meta: databaseType:bibtex;}
