%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[sigplan,10pt,review,anonymous]{acmart}
\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[sigplan]{acmart}\settopmatter{}


%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmConference[PL'18]{ACM SIGPLAN Conference on Programming Languages}{January 01--03, 2018}{New York, NY, USA}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%\citestyle{acmauthoryear}  %% For author/year citations
%\citestyle{acmnumeric}     %% For numeric citations
%\setcitestyle{nosort}      %% With 'acmnumeric', to disable automatic
                            %% sorting of references within a single citation;
                            %% e.g., \cite{Smith99,Carpenter05,Baker12}
                            %% rendered as [14,5,2] rather than [2,5,14].
%\setcitesyle{nocompress}   %% With 'acmnumeric', to disable automatic
                            %% compression of sequential references within a
                            %% single citation;
                            %% e.g., \cite{Baker12,Baker14,Baker16}
                            %% rendered as [2,3,4] rather than [2-4].


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from traditional SIGPLAN
%% proceedings format to PACMPL format must update the
%% '\documentclass' and topmatter commands above; see
%% 'acmart-pacmpl-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\makeatletter
\newcommand{\todo}[1]{%
\@latex@warning{TODO: \detokenize{#1} on page \thepage}%
\textcolor{red}{[\textbf{TODO:} #1]}}%
\makeatother

\begin{document}

%% Title information
\title[Short Title]{Full Title}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
\titlenote{with title note}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
\subtitle{Subtitle}                     %% \subtitle is optional
\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Jason Gross}
\authornote{now with MIRI}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{0000-0002-9427-4891}             %% \orcid is optional
\affiliation{
%  \position{Position1}
  \department{CSAIL}              %% \department is recommended
  \institution{Massachusetts Institute of Technology}            %% \institution is required
  \streetaddress{77 Massachusetts Avenue}
  \city{Cambridge}
  \state{MA}
  \postcode{02139}
  \country{USA}                    %% \country is recommended
}
\email{jgross@mit.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{Th√©o Zimmermann}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended

\author{Adam Chlipala}
%\authornote{with author1 note}          %% \authornote is optional;
%                                        %% can be repeated if necessary
%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position1}
  \department{CSAIL}              %% \department is recommended
  \institution{Massachusetts Institute of Technology}            %% \institution is required
  \streetaddress{77 Massachusetts Avenue}
  \city{Cambridge}
  \state{MA}
  \postcode{02139}
  \country{USA}                    %% \country is recommended
}
\email{adamc@csail.mit.edu}          %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
Text of abstract \ldots.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\section{Introduction}

Text of paper \ldots

\section{Improving the coverage of Coq's test suite}

\subsection{Context and objectives}

Shipping new releases of a compiler frequently can be a challenge
because catching regressions is not trivial, even with an extensive
test suite.
%
This is why, the Rust compiler, for instance, is tested not only on a
large test suite, but also on all the external Rust source code
available on GitHub.\footnote{As narrated by Pietro Albini in his talk
``Shipping a compiler every six weeks'', available at
\url{https://www.youtube.com/watch?v=As1gXp5kX1M} and whose transcript
is available at
\url{https://www.pietroalbini.org/blog/shipping-a-compiler-every-six-weeks/}.}

In the case of the Coq proof assistant, the development team decided
to shorten the release cycles not to six weeks but to six months, but
this still represented a significant challenge to do so reliably.
%
Therefore, in early 2017, they adopted a ``reverse'' continuous
integration, i.e., a continous integration configuration including a
large portion of compatibility testing with external Coq projects (Coq
projects maintained by different teams in different
repositories)~\cite{zimmermann:tel-02451322}.

This continuous testing of external Coq projects represents in itself
a continuous challenge because of the specificities of Coq's
evolution.
%
Indeed, as of today, Coq's evolution still includes many breaking
changes in each release (breaking changes that are evaluated,
validated and documented, and therefore cannot be classified as
regressions, but still break some of the tested projects).
%
Every time such breaking changes are introduced, Coq developers must
fix the tested projects for compatibility, because they would not be
usable for testing anymore if that was not done.
%
Furthermore, fixing external projects can help Coq developers assess
in more depth the practical impact of a breaking change.

A rough assessment shows that more than half of the time that a change
to Coq breaks at least one external tested project, the Coq test suite
still passes fully~\cite{zimmermann:tel-02451322}.
%
We interpret this as insufficient coverage of the Coq test suite with
respect to the features that are actually relied on by users.
%
Therefore, a primary objective of this work was to help improve the
coverage of the test suite by systematically extracting a minimal
reproducible example from any compatibility issue detected while
testing a change to Coq.

A secondary objective was to help Coq developers assess more easily
the kind of compatibility issues that they introduce with their
changes.
%
Indeed, every change to Coq is tested against millions of lines of
externally maintained Coq code.
%
Some of the tested projects can be difficult to navigate and
understand for Coq developers.
%
Therefore, extracting a minimal reproducible example of a
compatibility issue can help the developer to determine whether it is
a regression or a desirable change and therefore to decide whether to
fix the change to Coq or the tested project for compatibility.

\subsection{Technology}

\subsubsection{Extending the bot of the Coq development team with a CI minimization feature}

\subsubsection{Adapting the bug minimizer for minimizing compatibility issues}

\subsubsection{Using GitHub Actions to run the bot}

\subsection{Evaluation}

\section{How the bug minimizer works}
Broadly, the bug minimizer is an adaptation of delta-debugging for Coq developments.

\subsection{The Spec}\label{sec:spec}
The bug minimizer runs a given development through Coq and parses the error message.
The goal is to construct a smaller, more self-contained script that generates the same error message.
An additional constraint that we place on the minimizer is that the proof script generating the error message should be left untouched.
This allows users to write proof scripts such as
\begin{verbatim}
some_tactic;
let G := match goal with |- ?G => G end in
lazymatch G with
| buggy_goal => fail 0 "bug remains"
| _ => fail 0 "bug disappeared!" G
end.
\end{verbatim}
to customize the desired reproducing case, and the minimizer will not decide that it can minimize the entire file to something silly like \verb|Goal False. fail 0 "bug remains"|.

For CI minimization, we furthermore want to preserve the lack of error message on one version of Coq while preserving the error message on the more recent, proposed version of Coq.

\subsection{Broad Insights}
There are two broadly interesting insights used to make delta-debugging run well with Coq:
\begin{enumerate}
\item
  Since Coq forbids forward-reference, removing earlier statements almost never allows the removal of later statements.
  Hence we can mostly just make a linear pass over statements in reverse order, attempting to remove one at a time.
\item
  In our goal to get the shortest reproducing test case as quickly as possible, it behooves us to first make any changes that might significantly speed up the execution time, and only after we're done with all of the changes that might improve running time should we try to further minimize the file with changes that are unlikely to impact compile time.
  The slowest part of almost all Coq developments is proof scripts.
  Hence it behooves us to attempt to remove proof scripts as early as possible.
  Coq has a couple of mechanisms for removing proof scripts without removing the theorems and definitions being proven (the commands \verb|Admitted| and \verb|Admit Obligations| as well as the \verb|admit| tactic).
  Replacing proof blocks with these commands, rather than just removing proof scripts, allows us to make much smaller and faster examples than might otherwise be possible.
\end{enumerate}

In addition to this, there are four fundamentally different sorts of actions the bug minimizer needs to perform, all of which have their own laundry list of corner cases which drive various adaptations in the minimizer to handle these cases.
The sorts of actions are:
\begin{enumerate}
\item
  Determine the failing file, the error message, and the command-line arguments necessary to reproduce the error message.
\item
  Determine what it means for the error message to ``be preserved'' (we do not want to require, for example, that source-code line number attached to the error message is always the same).
\item
  Perform source code transformations on the failing code while preserving the error message, either replacing code with other code (as when admitting proof scripts) or removing statements.
\item
  Inline dependencies of the file, making it more stand-alone.
\end{enumerate}

\subsection{Control Flow}
Bug minimizer execution has a couple of steps.
We include here the steps that are performed by external scripts for CI minimization.

Steps before the bug minimizer is invoked:
\begin{enumerate}
\item Unpack and install both the succeeding and failing versions of Coq and corresponding developments.
\item Replace the Coq binaries with wrappers that print out the arguments that Coq was called with, as well as COQPATH and pwd.
  \todo{Maybe add text somewhere that I (Jason) think this is a pretty cool way of not having to deal with varied build systems of CI developments.
    Note that there are a bunch of subtleties here: if we don't get access to COQPATH, we won't be able to build some developments.
    If we don't print out the pwd, we can find the right bug file by absolutizing the arguments to coq, but this breaks output tests, cf https://github.com/math-comp/hierarchy-builder/issues/256.}
\item Run Coq on the succeeding and failing developments, ensuring that the version that should pass does in fact pass, and the version that should fail has a recognizable error message.
\item Parse the build log to determine the buggy file name and the arguments to pass to Coq.
  This workflow means that we don't need to directly interface with the varied build systems of various contributions on the CI.
\end{enumerate}

Control flow of the bug minimizer:
\begin{enumerate}
\item Run Coq on the buggy file.
\item Parse the error message, ensuring that it matches with the error message from the build log.
  (Note that there are a bunch of error message changes that we allow, such as changing evar numbers and universe numbers, etc.)
\item Repeat the following steps until a fixed point is reached, skipping any steps that change the error message in a forbidden way.
\begin{enumerate}
\item Remove comments, inserting a header comment with metadata about minimization statistics.
\item Insert a further header which defines the \verb|admit| tactic.
  We must define this tactic ourselves to handle files which build with a non-standard standard library (such as HoTT) and hence don't have access to \verb|Coq.Compat.AdmitAxiom|.
  To support multiple versions of Coq, we need to feature-test Coq to see what fragment of code grants us access to Ltac without loading the standard library; this feature-test is done once and for all for a single run of the bug minimizer.
\item Split \verb|Require| statements from \verb|Import|/\verb|Export|, disambiguating the statements at the same time.
  (If we don't disambiguate them, the \verb|Import|s might point to the wrong module.)
\item Move the \verb|Require| statements to the top of the file, transitively closing them (this allows us to remove \verb|Require| statements which are only needed to transitively require other files).
\item Parse the file into statements (with exactly two exceptions, statements in Coq end with \verb|.| or \verb|...| followed by whitespace; the exceptions are \verb|{| and \verb|}|).
  Note that this is complicated by needing to handle strings which contain a full stop followed by whitespace, and by the fact that comments in Coq are well-balanced and nestable and can contain strings which themselves contain comment identifiers without nesting further comments.
\item Remove statements after the line which generates the error.
\item Split the statements into structured blocks, one per definition/proof.
  We should not assume that we can remove lines from the end of a proof without breaking things, so we treat each theorem/lemma/definition block, combined with its proof, as a unit.
  This is made simpler by the fact that Coq strongly discourages nested proofs, and by the fact that Coq generally forces definitions and their bodies to be side-by-side.
  There are a couple of exceptions to this strategy, that have dedicated passes for handling them:
  \begin{itemize}
  \item \verb|Program| \verb|Definition|s, \verb|Fixpoint|s, etc, have \verb|Obligation| blocks which can be interwoven with other definitions.
    The solution here is to replace such \verb|Obligation| blocks with \verb|Admit Obligations|, which is thankfully a no-op when no obligations are present.
    \todo{Insert some code showing how minimization of program definitions proceeds with admit obligations}
  \item Sections, modules, and module types have paired vernacular delimiters.
    Currently there is some code to eliminate empty blocks, but it doesn't work very well, and misses many cases.
    There's an open feature request for a \verb|Try| vernacular command at https://github.com/coq/coq/issues/15051, which would solve the issue of coupled commands in general.
  \end{itemize}
\item Repeat the following steps until a fixed point is reached (order presented here is not faithful to the minimizer):
  \begin{itemize}
  \item Remove each structured block (whose removal does not change the error message), one at a time, from the end of the file to the beginning of the file.
  \item Replace proof scripts with \verb|Admitted|.
    (There's some nuance about the best ordering strategy to try here, whether to first try all the \verb|Qed| lemmas, whether to first try all lemmas and definitions at once, or whether to just go one at a time in reverse order.)
    Also, we actually replace them with \verb|admit. Defined.| so that previously unfoldable constants remain unfoldable.
    Technically we should try \verb|Admitted| when the proof script previously ended with \verb|Qed| and replacing with \verb|admit. Defined.| fails, because it might be the case that some later tactic relies on this definition not being unfoldable, but we have not encountered such a case yet, and it seems quite unlikely.
  \item Replace \verb|abstract tac| with \verb|admit|, potentially simplifying proof scripts and decreasing dependencies.
  \item Split \verb|Definition foo args : ty := body.| into \verb|Definition foo args : ty.| and \verb|Proof. refine (body). Defined.| so that such definitions can potentially be admitted later.
  \item Replace \verb|Module Foo| with \verb|Module Export Foo|, potentially allowing the removal of \verb|Import| statements later, and potentially eventually allowing the removal of the module itself.
  \item Split \verb|Import| and \verb|Export| statements containing multiple modules into separate statements, so they can be removed separately.
  \item Early on, some likely-to-succeed steps are tried, such as removing tactics, \verb|Variable| and \verb|Context| statements, and definitions which are not referred to at all after their definition.
    This step is superseded by removing each and every structured block one at a time, but may result in faster minimization.
  \end{itemize}
\item Finally, before repeating the loop, attempt to inline a dependency which has not yet been inlined.
  Inlining dependencies is an interesting technical challenge, due to nuances in how Coq binds names and handles global state.
  \todo{write more text about what's required here, and what still remains}
\end{enumerate}
\end{enumerate}

\subsection{Walkthrough via Examples}

\subsubsection{Infrastructure around Invoking the Minimizer}
As described in \autoref{sec:spec}, the goal of the minimizer is to take a CI development that succeds on the tip of master and fails on a given PR, and emit a small, stand-alone file which succeeds on master and fails in the same way \todo{same modulo universes, etc, stick this somewhere} on the PR.
\todo{Should we cite \url{https://github.com/dsw/delta\#do-a-controlled-experiment} about passing coqc, a la ``Below we don't just minimize a file that causes Oink to produce an error message, we minimize a file that causes gcc to accept AND oink to reject in a specific way. That is, the test delta does is a controlled experiment, where gcc is the control. Ignoring this aspect of the problem seems to be a frequent mistake of first time users.''}

In order to do this efficiently, we re-use the CI artifacts from Coq.
We download the pre-built versions of Coq from master and from the tip of the PR.
From just these artifacts and the name of the failing CI development, we must assemble enough information to run the bug minimizer.
We replicate Coq's generic CI workflow to install Coq as well as any dependencies of this CI development, into different directories: one for the version of Coq that's supposed to pass, and another for the version of Coq that's supposed to fail.
We also reuse Coq's generic CI workflow to figure out the error message and the failing file which we want to minimize.
Much like \todo{cite https://github.com/dsw/build-interceptor}, rather than trying to parse the build setup of various CI developments, we merely wrap the Coq binaries to intercept the build-system calls, and print out the relevant information to stderr.
\todo{Add a note about future work for redirecting things to a log file from within the wrapper, so that we don't change the build output at all, which would, perhaps, allow us to minimize coq-tools itself, maybe}
The relevant information in this case, is the current working directory of coqc, the environment variable \texttt{COQPATH}, the command line used to invoke the binary, and the relative path of the file that coqc is invoked on.
We need \texttt{COQPATH} to ensure that we have the right search path for the dependencies of coqc.
\todo{maybe explain COQPATH somewhere?}
We need the command line arguments so that we know what flags to tell the bug minimizer to pass to coqc.
We could in theory elide the file name and the current working directory, as long as we changed all relative paths to absolute paths before printing the command line.
(Unless the file uses directives like \texttt{Cd} or \texttt{Add LoadPath} with relative paths.
However, we don't currently test nor support these cases directly.
\todo{should we include this paranthetical?})
Note that we \emph{must not} change relative paths to absolute ones when passing arguments along to coqc, because the output of coqc is sensitive to the difference between relative and absolute paths, and this can mess up output tests (and did in the past, for example with ci-elpi).
We can locate the error message by looking for the last instance of \texttt{File "$f$", line $\ell$, characters $n$-$m$:} followed immediately by a line beginning with \texttt{Error}.
(Note that warning messages also emit the \texttt{File $\ldots$} line, but we don't want to catch warnings.)
We look for the last instance of the wrapper debug printout information which points at the same file, though, so long as we were careful to always build single-threadedly, we could instead just look for the most recent debug printout before the error message.

Given this information, we adjust the arguments so that we can tell the bug minimizer where the dependencies live both for the passing and failing versions of Coq.
We then pass this information to the bug minimizer:
\begin{itemize}
\item the location of the file to be minimized;
\item the log file containing the error message, which must match the error message that the minimizer believes the file produces;
\item the location of the \verb|coqc|, \verb|coqtop|, and \verb|coq_makefile| for the tip of the PR
\item the location of the \verb|coqc| for the master branch
\item the location of the dependencies for both the passing and failing versions of Coq, parsed from the command line arguments and from walking the directories in \texttt{COQPATH}
\item any arguments to \verb|coqc| which are neither naming dependency locations nor known to be both irrelevant to the processing of the file and counter-productive to the minimizer's operation (such arguments are \verb|-batch| which applies only to \verb|coqtop|, \verb|-time| which will only make logs of the minimizer much longer, and \verb|-noglob|, \verb|-dump-glob|, and \verb|-o|, which interfere with the generation of outputs used by the minimizer).
\end{itemize}

Henceforce, we will assume that we have all of this information at hand, and speak only of how to minimize files.

\subsubsection{The Basics}
The simplest function of the bug minimizer is to remove unneeded lines.
For example, if a Coq PR breaks the \texttt{rewrite} tactic (an admittedly simplistic example in this generality), we might want to minimize a file such as
\begin{verbatim}
Definition zero := 0.
Definition one := 1.
Definition two := 2.
Lemma foo : forall x, x = zero -> S x = one.
Proof. intros x H. rewrite H. reflexivity. Qed.
\end{verbatim}
into
\begin{verbatim}
Definition zero := 0.
Definition one := 1.
Lemma foo : forall x, x = zero -> S x = one.
Proof. intros x H. rewrite H.
\end{verbatim}
Note that the definition \texttt{two} has been removed.

Here it suffices to (a) remove all statements after the error, and (b) try removing each line one at a time.
Since Coq is mostly not sensitive to whitespace, we want to remove statements, rather than lines.

In almost all Coq code (exception: custom grammar entries, inline elpi code, and the standalone statements \verb|{| and \verb|}|), a statement is any sequence of characters which ends with a \verb|.| or a \verb|...| followed by either whitespace of the end of the document, where the ending full stop(s) are neither in the middle of a string (delimited by \verb|"|) nor a comment.
In Coq, comments begin with \verb|(*| and end with \verb|*)|.
Comments are nested, so \verb|(* (* *) still in a comment *)| is all one comment.
In Coq, strings start and end with \verb|"|.
Furthermore, strings can occur in comments, so \verb|(* "(*" *)| is a well-balanced comment.
Note, however, that \verb|*)| is a valid token outside of comments, such as \verb|(simpl in *); idtac|.

We may someday depend on a proper Coq parser (such as SerAPI), but we currently do in-house parsing.
Even if we move to depending on a proper parser, we will sometimes have to do transformations on files where we cannot do full parsing.
See \autoref{sec:glob-for-inline-installed-files-without-parsing} for more details.
\todo{make sure \autoref{sec:glob-for-inline-installed-files-without-parsing} exists}
Furthermore, we continue to support versions of Coq all the way back to 8.5, in part because minimization is also useful for porting older Coq developments to newer versions of Coq, and so any plugin-based parsing will not fully subsume the existing parsing methods.

We currently have three methods of parsing Coq documents:
\begin{enumerate}
\item Parsing based on the details laid out above.
\item Using \texttt{coqc -time} to get byte ranges for each statement.
  Note that these are \emph{byte} ranges and not character ranges, so we have to be careful when documents contain unicode.
\item Using \texttt{coqtop -emacs -time}, which, in addition to providing byte ranges for statements, also provides information about which lines are part of which definitions (via the emacs prompt), and which lines close definitions (via the \texttt{\emph{foo} is defined} message).
  Note that \verb|-emacs| is technically meant for legacy interaction with the ProofGeneral IDE, so we may someday have to move to a different API.
  Hopefully by the time \verb|-emacs| is removed, we'll be ready to use plugin-based parsing via SerAPI or similar.
\end{enumerate}

Because Coq forbids forward references (definitions cannot refer to any identifiers that have not yet been added to the global environment, and documents are processed serially), we can remove all lines after the line where the error occurs without risking a change in error messages.
Note that the error message line indicator is not always accurate; the recent bug at \url{https://github.com/coq/coq/issues/15073}\todo{formatting of link} was an instance where the error location was mis-reported.

This lack of forward referencing also means that we generally don't need to do any sort of non-local search on removing statements.
Since removing an earlier statement almost never enables removing a later statement, we can generally just try removing statements one at a time, in reverse order.

Consider now a file such as.
\begin{verbatim}
Definition zero := 0.
Definition one := 1.
Definition two := 2.
Lemma irrelevant : two = 2.
Proof. reflexivity. Qed.
Lemma foo : forall x, x = zero -> S x = one.
Proof. intros x H. rewrite H. reflexivity. Qed.
\end{verbatim}
Since Coq forbids nested lemmas, removing statements one at a time will not work, as the state
\begin{verbatim}
Definition zero := 0.
Definition one := 1.
Lemma irrelevant : two = 2.
Proof. reflexivity.
Lemma foo : forall x, x = zero -> S x = one.
Proof. intros x H. rewrite H.
\end{verbatim}
results in an error about nested proofs.

We instead group statements into \emph{definition} blocks to be removed all at once.
We get information about definitions by parsing the output of \texttt{coqtop -emacs -time}, as mentioned above.
This way, we can remove
\begin{verbatim}
Lemma irrelevant : two = 2.
Proof. reflexivity. Qed.
\end{verbatim}
all at once.

We could in theory deal with more complicated nesting structure, for example trying to remove an entire section or module at a time.
The tool at \url{https://github.com/dsw/delta#exploit-nested-structure} \todo{better citation} is in fact built around preprocessing the file into one that exposes nested structure clearly, and then removing well-parenthesized blocks.
However, removing statements, grouped into definitions as necessary, sufficies for removing time-consuming code.
(\todo{Find a better place for this theme, call it out more broadly:}%
In general, it's very important to remove any lines that can be removed that take significant compilation time, and much less important to remove lines that take basically no compilation time.
\todo{what more should be said about this?}
)

\paragraph{Admitting Proofs}
Another enormously useful transformation is \emph{admitting proofs}.
For example, suppose that some PR broke the ability of \verb|rewrite| to make use of lemmas proving equalities between propositions.
Consider the file:
\begin{verbatim}
Lemma complicated : True = False.
Proof.
  (* ... *)
  (* thousands of lines of proof taking minutes to compile *)
  (* ... *)
Qed.
Lemma boom : True -> False.
Proof. rewrite complicated.
\end{verbatim}
We cannot remove statements here, but we can minimize this file to
\begin{verbatim}
Lemma complicated : True = False.
Admitted.
Lemma boom : True -> False.
Proof. rewrite complicated.
\end{verbatim}

This is one of the domain-specific features of Coq that makes delta-debugging a significantly different problem than in other domains:
There are slow blocks of code that cannot be entirely removed without changing the error message, but they can be replaced by a much faster catch-all result.

There are some quirks to be aware of around this.

The first quirk is around unfolding.

Consider the file:
\begin{verbatim}
Lemma complicated : True = False.
Proof.
  (* ... *)
  (* thousands of lines of proof taking minutes to compile *)
  (* ... *)
Defined.
Lemma boom : True -> False.
Proof.
  pose complicated as H.
  unfold complicated in H.
  rewrite H.
\end{verbatim}
If we replace the proof script of \verb|complicated| with just \verb|Admitted.|, then the line \verb|unfold complicated in H| will fail with \verb|Error: complicated is opaque|.
We can work around this issue by copying the \verb|admit| tactic from \verb|Coq.Compat.AdmitAxiom|, which is effectively a tactic version of \verb|Admitted|:
\begin{verbatim}
Axiom proof_admitted : False.
Ltac admit := clear; abstract case proof_admitted.
\end{verbatim}
Now we can replace the long proof of \verb|complicated| with \verb|admit. Defined.|

Conversely, we might have a file where the error message relies on \emph{not} being able to unfold a lemma whose proof script ended with \verb|Qed|.
(For a very silly example, consider prefixing an essential tactic with \verb+unfold complicated ||+.)
Hence we must support both \verb|Admitted| and \verb|admit. Defined.| as replacements.

\todo{this subsubsection deserves a better structure, I think\ldots}

Additionally, we may want to admit some parts of the proof script without replacing all of it.
Currently, we use a rather conservative heuristic:
Coq has a tactical \verb|abstract| which executes the tactic it is passed as an argument, and makes the resulting proof term opaque.
Such subproofs should be able to be replaced with \verb|admit| without changing the behavior of the proof script.
To make this change more likely to succeed, we define \verb|admit| as \verb|abstract case proof_admitted| rather than \verb|clear; abstract case proof_admitted|.

Here is a case where this matters:
Consider the file
\begin{verbatim}
Section foo.
  Context (a : nat).
  Definition foo : nat.
  Proof.
    refine (_ + _).
    all: abstract exact a.
  Defined.
End foo.
Goal True.
  pose (foo 5) as x.
  lazymatch (eval unfold x, foo in x) with
  | ?x + ?y => idtac
  | ?v => fail 0 "bad" v
  end.
\end{verbatim}
If we replace \verb|abstract exact a| with \verb|clear; abstract case proof_admitted|, then the definition \verb|foo| no longer depends on \verb|a|, and the \verb|pose| line will fail with a type error.

In the future, when we do more fine-grained parsing of the Coq document structure, we may want to try replacing more subparts of proof scripts with \verb|admit|.
See \autoref{sec:future-work} for more details.

There are two more cavi
\todo{HERE}

\subsubsection{Coupled Removal}
\todo{this section}

There are a couple of exceptions to this.
The primary one is statements in Coq's \verb|Program| mode.\todo{cite}
For example, removing


\subsubsection{More Strategies for Minimizing Files}
\todo{this section}

\subsubsection{When are two error messages ``the same''?}
\todo{this section}

\subsubsection{Inlining Dependencies}
\todo{this section}


\begin{comment}

\subsection{Adaptations specific to Coq}
Coq has a number of quirks that enable efficient bug minimization, as well as a few quirks that seriously hinder bug minimization.
The quirks that enable efficient bug minimization are:
\begin{itemize}
\item lack of forward-references (definitions cannot refer to any identifiers that have not yet been added to the global environment);
\item emitting text files that describe how to hyperlink identifiers, for documentation purposes;
\item ending every comamnd in either one or three full stops, with only two exceptions (\verb|{| and \verb|}|);
\item
\end{itemize}
\subsubsection{Adaptations enabled by lack of forward references}
Because Coq forbids forward references, we can remove all lines after the line where the error occurs without risking a change in error messages.

Additionally, we can, by and large, remove lines in reverse order.
That is, if we removing line $n$ changes the error message, then first removing line $m$ for $m < n$ will almost never result in a success (that is, a lack of error message change) from removing line $n$ later.
This allows us to rely on a single work-horse pass that removes lines, one at a time, starting from the end of the file.

We say ``lines'' above, but in fact a line (a string of characters ended by a newline) is not the natural statement
\subsubsection{Comment Stripping}







Specific adaptations to delta debugging for working with Coq scripts, including
admitting proofs
splitting imports and requires
working in units of "an entire proof script / definition"
being able to work from the end of the file, due to lack of cyclic dependencies (with some minor exceptions, such as program obligations)
the work that it takes to inline one file into another
What specific features (both ones that are already present and ones that are requested) are necessary for producing self-contained single-file test-cases
Integration of delta-debugging into CI failures, in particular:
This is feasible compute-wise (+ some graphs / stats on typical minimization runtime)
We found an interaction mode that seems to work well (+ some feedback on other interaction modes)
(2)
I'm not sure what the overall story for the paper should be ("we did a cool thing, here it is"? or "we did a useful thing, here's what it took and what you need to know if you want to do a similar thing"? or something else?)
Here are some sections that are probably worth including:
What the bug minimizer does (Coq project + error message -> minimal test case) and how it works (delta debugging on maintaining the error message + various details)
How the integration with Coq's CI and GH Actions and coqbot works and what it does (allows PR authors to turn "this failed" into an actually useful test-case that can be further minimized and/or included in the test-suite and/or mined for insight into what changed, maybe note also that this improves on debuggability of error messages --- the error message + source is generally not enough to figure out what's going wrong when the CI fails, Coq doesn't have unit tests because ???, this closes the gap)
Future work including:
Automatic minimization and maintenance of test-cases for bugs reported on Coq's issue tracker
Multi-file minimization
Better support for when bumping the branch targeted by the CI causes a failure (rather than it being a change in Coq)
Various issues that prevent complete inlining of files

\end{comment}

\section{Future Work}\label{sec:future-work}
\todo{organize this section}

Rather than emitting the information to stderr when wrapping coqc, we could emit it to a file (have to be careful about paralell builds, though).
See \url{https://github.com/coq-community/run-coq-bug-minimizer/issues/11}.

Use a proper Coq parser.
See \url{https://github.com/JasonGross/coq-tools/issues/56}.

When removing a statement fails, try removing all statements that generate different error messages, seeing if we can recover the original error message.
This should probably be done with incremental compilation.
This would allow us to drop many specific passes (such as removing empty sections and modules).
Furthermore, if we hook into a proper Coq parser that allows discovering well-balanced structure more fine-grained than a particular definition, we could plausibly use this sort of thing to be able to remove specific fields from records, for example.
See \url{https://github.com/JasonGross/coq-tools/issues/73} and \url{https://github.com/JasonGross/coq-tools/issues/88}.

Make use of \verb|Set Suggest Proof Using| to enable removal of proof scripts that only matter for specifying the arguments of a lemma.
See \url{https://github.com/JasonGross/coq-tools/issues/68}.
Example:
\begin{verbatim}
Section foo.
  Context (x y : nat) (p q : x = y).
  Lemma silly : True -> x = y.
  Proof. intro; exact p. Qed.
End foo.
Definition bar := @silly 0 0 eq_refl I.
Fail Check bar.
\end{verbatim}
This file should be able to be minimized to
\begin{verbatim}
Section foo.
  Context (x y : nat) (p q : x = y).
  Lemma silly : True -> x = y.
  Proof using p. Admitted.
End foo.
Definition bar := @silly 0 0 eq_refl I.
Fail Check bar.
\end{verbatim}
This is useful when the proof script is much longer than \verb|intro; exact p|.

Support incremental compilation.
Removing a line at the end of the file should not require recompiling the initial segment.
See \url{https://github.com/JasonGross/coq-tools/issues/87}.

Remove well-balanced structures (sections, modules, etc) before we try to remove lines in those structures.
See \url{https://github.com/JasonGross/coq-tools/issues/89}.

\section{Evaluation of Results}

\todo{Theo}

\subsection{Research questions}

We want to evaluate how well the Coq bug minimizer and its integration into Coq's CI setup, via coqbot, works to achieve our stated objectives which we remind below:

\begin{enumerate}
\item Improve the coverage of the test suite by systematically extracting minimal test cases from compatibility issues that are detected in external projects tested in Coq's CI.
\item Help Coq developers assess more easily the nature of compatibility issues they introduce with their changes.
\end{enumerate}

For this purpose, we specify several research questions to investigate:

\begin{description}
\item[RQ1:] How often does the minimizer successfully produce a reduced example from the CI failures it was triggered on?
\item[RQ2:] What time does it take to run on the cases where it was triggered?
\item[RQ3:] How often does it manage to produce a reduced case that is sufficiently short and does not depend on anything beyond the standard library of Coq?
\item[RQ4:] Does it help Coq developers understand CI failures?
\item[RQ5:] Does it help Coq developers expand the coverage of the test suite?
\end{description}

\subsection{Data collection}

To support replicating the results, all our data collection and analysis code is made available as Jupyter notebooks and our datasets are made available as CSV files.\footnote{\todo{Theo}}

To know in which context the bug minimizer was triggered and how it answered, we fetch comments from pull requests in the GitHub repository using GitHub's GraphQL API.
%
We look for all the pull requests with the words ``coqbot ci minimize''.
%
These correspond to all the pull requests where coqbot offered the possibility of minimizing a CI failure. For each of these pull requests, we fetch all the comments, with their author, time and date and body text.
%
We detect triggers of the minimizer by looking at comments by authors other than coqbot with the words ``coqbot ci minimize''.
%
We exclude pull requests authored by one of the co-authors of this paper as these pull requests were mostly for testing the minimizer integration and debugging issues.

After several months in production, we added a sentence to the comment posted by coqbot with the results of the minimizer asking users to fill a very short survey about their experience with it.
%
However, this message alone did not attract any answer (probably because it was not visible enough, or not targetted enough to specific users).

To alleviate this problem and also to collect data on past runs of the minimizer, we posted an issue in Coq's bug tracker tagging all the people that triggered the bug minimizer or were the author of a pull request where the bug minimizer was triggered.
%
For each of the tagged users, we listed the pull requests that were relevant to them (either as an author or as a triggerer) and provided a link to the survey (with the pull request number pre-filled).
%
The survey asked in particular how useful the minimizer was to the respondent, if it helped understand the impact of the pull request on external projects and if the minimized test case was used to extend the test suite.
%
The posted issue was auto-generated from our data on the bug minimizer runs.

This issue allowed us to collect 19 answers from 7 different respondents. \todo{Update if needed.}
%
The data collected through this survey are also available as a CSV file, which we import and analyze in our Jupyter notebook.

\subsection{Data analysis}

To answer our first three research questions, we look at all the pull requests and all the projects where the CI minimizer was triggered.
%
To avoid double-counting multiple runs on the same CI failure, we only look at the first CI minimizer triggers on a given pull request and a given project.

When the minimizer is triggered, the bot answers with a comment ``I have initiated minimization \ldots'' or ``I am now running minimization \ldots'', providing the list of projects on which it is being run.
%
Next, when it finishes minimizing a project, it produces a comment starting with ``Minimized File''.
%
The comment contains the minimized file, truncated to 700 lines \todo{Provide exact number}.
%
The comment may also contain ``interrupted by timeout, being automatically continued'' if the minimization process timed out and has to be restarted to go further, which the bot automatically does.
%
We ignore these comments, only looking for final reduction outputs.
%
Finally, the bot posts a comment starting with ``Error: Could not minimize file'' when it was not able to minimize the requested failure, for instance, because it could not reproduce it or could not reproduce the successful run on the base branch.

We match comments indicating the start of the minimization with comments indicating the end of it, and use these two comments to determine if the minimizer was able to produce a reduced example, how long it took and if the reduced example was sufficiently short and self-contained.

\subsection{Results}

\subsubsection{RQ1: How often does the minimizer produce a reduced example?}

We have identified 155 CI failures for which minimization was started (very often, several minimization runs are started in the same comment).
%
For 131 of these (85\%), the bot eventually answers with a reduced example.
%
In 16 cases, the bot reports that minimization was unsuccessful.
%
\todo{Investigate manually the 16 cases and report on the causes.}
%
In 8 cases, there was no matching comment marking the end of minimization.
%
\todo{Investigate manually the 8 cases and report on the causes.}

\subsubsection{RQ2: What time does it take to run on the cases where it was triggered?}

On the 131 successful runs, we compute the duration as the time delta between the start and the end comments.
%
Note that while this precisely evaluates the time that developers using the minimizer had to wait for the results, it can overestimate the actual time spent by the minimizer on the example, if the minimizer run was queued for a while before starting to run in GitHub Actions.

The minimal observed duration is a little above 2 minutes (131 seconds) and the maximum observed duration is close to 20 hours (71665 seconds).
%
50\% of the runs take less than 15 minutes (910 seconds).
%
70\% of the runs take less than 53 minutes (3208 seconds).
%
80\% of the runs take less than 108 minutes (6467 seconds).
%
90\% of the runs take less than 5.3 hours (19219 seconds).
%
This is to compare with the time it can take to build a single project (sometimes, more than an hour).

\todo{An analysis project by project, comparing with the time it takes to simply build the project?}

\subsubsection{RQ3: How often does it produce a short and self-contained test case?}

\todo{}

\subsubsection{RQ4: Does it help Coq developers understand CI failures?}

We got 19 answers to our survey, from 7 different people.
%
14 of these answers where about pull requests where the respondent had triggered the minimizer themselves (and 5 where about pull requests which the respondent authored but where they did not trigger the minimizer).

The answers we got are very contrasted between the triggerers and the non-triggerers.
%
On the one hand, for each of the 5 responses from authors who did not trigger the minimizer themselves, the response to the survey indicated that the minimizer was not useful to the respondent and did not help them understand the CI failure.
%
On the other hand, 9 out of 14 responses from triggerers indicated that the minimizer was useful (3 somewhat useful and 6 very useful).
%
The next question on whether it helped diagnose the CI failure was optional but a majority of the triggerers that answered (5 out of 9) said it had helped.

\todo{Write about why people said the minimizer was not useful.}

\subsubsection{RQ5: Does it help Coq developers expand the coverage of the test suite?}

We also asked to the users of the minimizer if they used the output of the minimizer to extend the test suite of Coq (as the minimizer itself suggests when its reduced test case is short enough to fit in a comment).
%
The users who did not find the minimizer useful never answered positively to this question.
%
However, among the users who found the minimizer useful, a majority (5 out of 8) said they had used the output of the minimizer to extend the test suite of Coq.
%
In one case, the respondent explained that while the minimizer had been very useful by quickly identifying the reason of the CI failure, they had not used its output to extend the test suite because the reason was that the tested project used a deprecated feature that was being removed.

\todo{Manual analysis of how people extended the test suite}

\subsection{Threats to validity}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


\nocite{*}

%% Bibliography
\bibliography{coq-bug-minimizer.bib}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
